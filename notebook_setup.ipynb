{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn.cluster\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from six import iteritems\n",
    "\n",
    "import gensim\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from Litho.nlp_funcs import *\n",
    "from Litho.similarity import (check_similarity, match_lithcode, jaccard_similarity, \n",
    "                              calc_similarity_score, print_sim_compare)\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "path = 'example_data'\n",
    "lith_data = 'sampled_bores.csv'\n",
    "path_to_data = os.path.join(path, lith_data)\n",
    "\n",
    "lith_df = pd.read_csv(path_to_data, index_col='HydroCode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've modified and moved out the functions defined in the example script, which are imported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'example_data'\n",
    "lith_data = 'sampled_bores.csv'\n",
    "path_to_data = os.path.join(path, lith_data)\n",
    "\n",
    "lith_df = pd.read_csv(path_to_data, index_col='HydroCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lith_df.loc[:, ['MajorLithCode', 'Description']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use the MajorLithCode to inform our clustering (minor appears to be always empty). \n",
    "\n",
    "Unfortunately, there are 99 entries in the example set with unknown or numerical values (as shown below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_unknown_or_numeric = (lith_df.MajorLithCode == 'UNKN') | lith_df.MajorLithCode.str.isnumeric()\n",
    "lith_df.loc[is_unknown_or_numeric, 'MajorLithCode'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lith_df.loc[is_unknown_or_numeric, ['BoreID', 'MajorLithCode', 'Description']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lith_df.loc[~is_unknown_or_numeric, 'MajorLithCode'].unique()), \"Unique LithCodes that are not UNKN or numeric\")\n",
    "print(lith_df.loc[~is_unknown_or_numeric, 'MajorLithCode'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each unknown entry, can we find a comparable entry with the same terminology in the description?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
    "stopw2 = ['redish', 'reddish', 'red', 'black', 'blackish', 'brown', 'brownish',\n",
    "          'blue', 'blueish', 'orange', 'orangeish', 'gray', 'grey', 'grayish',\n",
    "          'greyish', 'white', 'whiteish', 'purple', 'purpleish', 'yellow',\n",
    "          'yellowish', 'green', 'greenish', 'light', 'very', 'pink','coarse',\n",
    "          'fine', 'medium', 'hard', 'soft', 'coloured', 'multicoloured',\n",
    "          'weathered', 'fractured']\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(stopw2)  # add the additional stopwords above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = lith_df.loc[is_unknown_or_numeric, 'Description'].values \n",
    "\n",
    "print(\"Attempting to fill in {} unknown MajorLithCode based on provided descriptions\".format(len(subset)))\n",
    "unkn_cache = {}\n",
    "for i in tqdm(subset):\n",
    "    \n",
    "    if i not in unkn_cache:\n",
    "        tmp_df = lith_df.loc[~is_unknown_or_numeric, ['Description', 'MajorLithCode']]\n",
    "        matches = tmp_df.apply(match_lithcode, args=(i, stopw2, ), axis=1)\n",
    "        counts = Counter(matches.dropna().values)\n",
    "        \n",
    "        try:\n",
    "            lith_code, num_occur = counts.most_common()[0]\n",
    "            if num_occur < 3:\n",
    "                raise IndexError  # Not enough to match lith code\n",
    "        except IndexError:\n",
    "            continue  # Could not find any matches!\n",
    "        # End try\n",
    "\n",
    "        # print(i, f' -> {lith_code} ({num_occur})')\n",
    "        unkn_cache[i] = lith_code\n",
    "    else:\n",
    "        lith_code = unkn_cache[i]\n",
    "    # End if\n",
    "    \n",
    "    lith_df.at[lith_df.Description == i, 'MajorLithCode'] = lith_code  # update lith code\n",
    "# End for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_unknown_or_numeric = (lith_df.MajorLithCode == 'UNKN') | lith_df.MajorLithCode.str.isnumeric()\n",
    "print(\"After clean up\", len(lith_df.loc[~is_unknown_or_numeric, 'MajorLithCode'].unique()), \"unique LithCodes that are not UNKN or numeric\")\n",
    "print(lith_df.loc[~is_unknown_or_numeric, 'MajorLithCode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "\n",
    "lith_code_desc = lith_df.loc[:, ['MajorLithCode', 'Description']]\n",
    "for row in lith_code_desc.itertuples():\n",
    "    allwords_stemmed = tokenize_and_stem(row.Description, stopwords) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend([allwords_stemmed]) #extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(row.Description, stopwords)\n",
    "    totalvocab_tokenized.extend([allwords_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(totalvocab_tokenized),  np.shape(totalvocab_stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of entries\", len(lith_code_desc.index))\n",
    "lith_code_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## used gensim instead of cosdisimilarity from sklearn due to the huge distance matrix\n",
    "dictionary = gensim.corpora.Dictionary(totalvocab_stemmed)\n",
    "once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "dictionary.filter_tokens(once_ids)\n",
    "dictionary.compactify()\n",
    "print(dictionary)\n",
    "# dictionary.save(path+'/dictio.dict')\n",
    "# store the dictionary, for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in totalvocab_stemmed]\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim.corpora.MmCorpus.serialize(path+'corpus.mm', corpus)  # store to disk, for later use\n",
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "sims = gensim.similarities.Similarity(path, tf_idf[corpus],\n",
    "                                      num_features=len(dictionary))\n",
    "\n",
    "x, y = [], []\n",
    "for n, i in enumerate(corpus[0:50]):\n",
    "    dist = 1-sims[tf_idf[i]]\n",
    "    # print(dist, len(dist))\n",
    "    if i == 0:\n",
    "        x0, y0 = 0, 0\n",
    "    elif i == 1:\n",
    "        x0, y0 = 0, dist[0]\n",
    "    else:\n",
    "        dp1p2 = dist[0] + dist[1]\n",
    "        dp1pn = dp1p2 + dist[1]\n",
    "        dp2pn = dist[0] + dp1p2\n",
    "        A = (dp1p2**2 + dp1pn**2 - dp2pn**2)/(2*dp1p2*dp1pn)\n",
    "        x0, y0 = dp1pn*np.cos(A), dp1pn*np.sin(A)\n",
    "    x.append(x0)\n",
    "    y.append(y0)\n",
    "# End for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "\n",
    "The problem seems that as we are converting to a 2D plane, and using the first two descriptions as references ('sand' and 'clay'), in the plane different categories are being plotted at the same location and distance from these descriptions. Other issue is that it doesn't differentiate by the order in the description. Thus, sandy clay is plotted at the same location that clayey sand..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "lith_code_desc = lith_df.loc[:, ['MajorLithCode', 'Description']]\n",
    "# Filter to unique combinations of LithCode and Description\n",
    "lith_code_desc = lith_code_desc.groupby(['MajorLithCode','Description']).size().reset_index().rename(columns={0: 'count'})\n",
    "warnings.warn(\"WARNING - Filtering to unique LithCode and Description, which may not be desirable in future!\")\n",
    "\n",
    "lith_desc = lith_code_desc.Description\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(x, y)\n",
    "for i,n in enumerate(lith_desc[0:50]):\n",
    "    plt.text(x[i],y[i],n)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lith NLP",
   "language": "python",
   "name": "lith-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
